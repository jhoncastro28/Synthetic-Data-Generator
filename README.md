# Generador de Datos SintÃ©ticos con GAN

Sistema completo para la generaciÃ³n de datos sintÃ©ticos utilizando Redes Generativas Adversarias (GANs) con TensorFlow/Keras.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un sistema robusto de generaciÃ³n de datos sintÃ©ticos que:

- Entrena modelos GAN (estÃ¡ndar y Wasserstein) para aprender la distribuciÃ³n de datos reales
- Genera datos sintÃ©ticos con alta fidelidad estadÃ­stica
- EvalÃºa la calidad mediante mÃºltiples mÃ©tricas personalizadas (CrC1RS)
- Soporta preprocesamiento automÃ¡tico de datos categÃ³ricos y numÃ©ricos
- Guarda modelos, preprocesadores y resultados para reproducibilidad
- Genera visualizaciones y reportes detallados

## ğŸš€ CaracterÃ­sticas

- **Arquitectura GAN Flexible**: Soporta GAN estÃ¡ndar, Wasserstein GAN y GAN condicional
- **Preprocesamiento AutomÃ¡tico**: Maneja datos numÃ©ricos y categÃ³ricos, normalizaciÃ³n y balanceo de clases
- **MÃ©tricas Avanzadas**: CrC1RS personalizado con correlaciÃ³n, consistencia, robustez y similitud
- **GestiÃ³n de Experimentos**: Sistema de pickle para guardar y cargar modelos, preprocesadores y estados de entrenamiento
- **Visualizaciones**: GrÃ¡ficas comparativas y evoluciÃ³n del entrenamiento
- **Sin Interfaz GrÃ¡fica**: Backend no-interactivo para ejecuciÃ³n en servidores

## ğŸ“¦ InstalaciÃ³n

### Requisitos

- Python 3.8+
- pip

### InstalaciÃ³n de Dependencias

```bash
# Clonar el repositorio
git clone <repository-url>
cd Synthetic-Data-Generator

# Instalar dependencias
pip install -r requirements.txt
```

### Dependencias Principales

```
tensorflow>=2.10.0
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0
scipy>=1.7.0
pyyaml>=5.4.0
```

## ğŸ—ï¸ Estructura del Proyecto

```
Synthetic-Data-Generator/
â”œâ”€â”€ configs/                    # Archivos de configuraciÃ³n
â”‚   â”œâ”€â”€ config.yaml            # ConfiguraciÃ³n principal
â”‚   â”œâ”€â”€ config_simple.yaml     # ConfiguraciÃ³n simplificada
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/                      # Datos (no incluidos en repo)
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ synthetic/
â”œâ”€â”€ results/                   # Resultados generados
â”‚   â”œâ”€â”€ models/               # Modelos entrenados (.pkl)
â”‚   â”œâ”€â”€ plots/                # Visualizaciones
â”‚   â”œâ”€â”€ synthetic_data/       # Datos sintÃ©ticos generados
â”‚   â”œâ”€â”€ preprocessors/        # Scalers y encoders
â”‚   â”œâ”€â”€ training_state/       # Estados de entrenamiento
â”‚   â””â”€â”€ metrics/              # MÃ©tricas guardadas
â”œâ”€â”€ src/                      # CÃ³digo fuente
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ generator.py      # Modelo generador
â”‚   â”‚   â”œâ”€â”€ discriminator.py  # Modelo discriminador
â”‚   â”‚   â””â”€â”€ gan.py           # Modelo GAN principal
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ trainer.py        # Entrenador del GAN
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_loader.py    # Carga y preprocesamiento
â”‚       â”œâ”€â”€ metrics.py        # Sistema de mÃ©tricas
â”‚       â””â”€â”€ pickle_manager.py # GestiÃ³n de persistencia
â”œâ”€â”€ main.py                   # Punto de entrada principal
â”œâ”€â”€ resume_training.py        # Continuar entrenamientos
â”œâ”€â”€ pickle_utils.py          # Utilidades para pickles
â””â”€â”€ requirements.txt          # Dependencias
```

## ğŸ’» Uso

### Uso BÃ¡sico

```bash
python main.py --data "datos.csv" --config configs/config.yaml --samples 1000
```

### ParÃ¡metros

- `--data`: Archivo CSV con los datos de entrenamiento (requerido)
- `--target`: Columna objetivo para clasificaciÃ³n (opcional)
- `--output`: Directorio para resultados (default: `results`)
- `--samples`: NÃºmero de muestras sintÃ©ticas a generar (default: 1000)
- `--config`: Archivo de configuraciÃ³n (default: `configs/config.yaml`)
- `--seed`: Semilla para reproducibilidad (default: 42)

### Ejemplos

#### Ejemplo 1: GeneraciÃ³n BÃ¡sica

```bash
python main.py \
  --data "Online Sales Data.csv" \
  --config configs/config_simple.yaml \
  --samples 1000 \
  --seed 42
```

#### Ejemplo 2: Con Columna Objetivo

```bash
python main.py \
  --data "medical_data.csv" \
  --target "diagnosis" \
  --config configs/config_medical.yaml \
  --samples 5000
```

#### Ejemplo 3: Continuar Entrenamiento

```bash
python resume_training.py \
  --experiment "gan_Online_Sales_Data_20251001_191424" \
  --data "Online Sales Data.csv" \
  --epochs 50
```

## âš™ï¸ ConfiguraciÃ³n

Edita `configs/config.yaml` para ajustar hiperparÃ¡metros:

```yaml
# ConfiguraciÃ³n de datos
data:
  train_split: 0.8
  validation_split: 0.2
  random_state: 42
  normalize: true
  balance_classes: true

# ConfiguraciÃ³n del modelo
model:
  latent_dim: 100
  generator_layers: [256, 512, 1024]
  discriminator_layers: [1024, 512, 256]
  dropout_rate: 0.3
  use_batch_norm: true

# ConfiguraciÃ³n de entrenamiento
training:
  batch_size: 64
  epochs: 1000
  learning_rate_g: 0.0002
  learning_rate_d: 0.0002
  beta_1: 0.5
  beta_2: 0.999
  save_interval: 50
  early_stopping_patience: 100

# ConfiguraciÃ³n de logging
logging:
  log_interval: 10
  save_plots: true
  use_tensorboard: false
```

## ğŸ“Š MÃ©tricas de EvaluaciÃ³n

### CrC1RS (Correlation, Consistency, Robustness, Similarity)

MÃ©trica personalizada que combina:

- **CorrelaciÃ³n (Î±=0.1)**: Similitud entre matrices de correlaciÃ³n
- **Consistencia (Î²=0.3)**: ComparaciÃ³n de estadÃ­sticas descriptivas
- **Robustez (Î³=0.4)**: Estabilidad ante perturbaciones
- **Similitud (Î´=0.2)**: Distancia de Wasserstein entre distribuciones

**InterpretaciÃ³n:**
- â˜…â˜…â˜…â˜…â˜… **0.80 - 1.00**: Excelente calidad
- â˜…â˜…â˜…â˜…â˜† **0.60 - 0.79**: Buena calidad
- â˜…â˜…â˜…â˜†â˜† **0.40 - 0.59**: Calidad regular
- â˜…â˜…â˜†â˜†â˜† **0.00 - 0.39**: Necesita mejoras

### MÃ©tricas Adicionales

- Distancia de Wasserstein
- Test Kolmogorov-Smirnov
- Divergencia de Jensen-Shannon
- MSE de medias y desviaciones estÃ¡ndar

## ğŸ“ˆ Resultados

DespuÃ©s de ejecutar el programa, encontrarÃ¡s:

### Datos SintÃ©ticos
- `results/synthetic_data.csv` - Datos generados en formato CSV
- `results/synthetic_data/final_synthetic.csv` - Datos finales del entrenamiento

### Visualizaciones
- `results/plots/final_comparison.png` - ComparaciÃ³n de distribuciones
- `results/plots/training_evolution.png` - EvoluciÃ³n de mÃ©tricas
- `results/plots/comparison_plots.png` - GrÃ¡ficas por caracterÃ­stica

### Reportes
- `results/evaluation_report.txt` - Reporte completo de evaluaciÃ³n
- `results/training_history.csv` - Historial de entrenamiento

### Modelos
- `results/models/*_generator_epoch_*.pkl` - Generadores guardados
- `results/models/*_discriminator_epoch_*.pkl` - Discriminadores guardados

### Preprocesadores
- `results/preprocessors/*_scaler.pkl` - Escaladores
- `results/preprocessors/*_encoder.pkl` - Codificadores

## ğŸ”§ Utilidades

### Listar Experimentos

```bash
python pickle_utils.py --action list
```

### Ver Detalles de Experimento

```bash
python pickle_utils.py --action details --experiment "gan_experiment_20251001"
```

### Comparar Experimentos

```bash
python pickle_utils.py --action compare --experiments exp1 exp2 exp3
```

### Exportar Experimento

```bash
python pickle_utils.py --action export --experiment "gan_experiment_20251001"
```

### Limpiar Archivos Antiguos

```bash
python pickle_utils.py --action cleanup --keep_last 5
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "All arrays must be of the same length"
- **SoluciÃ³n**: AsegÃºrate de usar la versiÃ³n corregida de `trainer.py`

### Error: Ventanas de matplotlib se abren
- **SoluciÃ³n**: Verifica que `matplotlib.use('Agg')` estÃ© al inicio de `trainer.py` y `metrics.py`

### Error: Memoria insuficiente
- **SoluciÃ³n**: Reduce `batch_size` en la configuraciÃ³n

### Bajo score CrC1RS
- **SoluciÃ³n**: Aumenta el nÃºmero de Ã©pocas o ajusta hiperparÃ¡metros

## ğŸ“ Notas TÃ©cnicas

- **Backend de matplotlib**: Configurado como 'Agg' (no-interactivo) para evitar ventanas emergentes
- **GestiÃ³n de memoria**: Los modelos se guardan en formato pickle para eficiencia
- **SincronizaciÃ³n de mÃ©tricas**: Las mÃ©tricas bÃ¡sicas se registran cada Ã©poca, las de validaciÃ³n segÃºn `log_interval`
- **Early stopping**: Implementado con paciencia configurable

## ğŸ¤ Contribuciones

Este proyecto fue desarrollado como parte del curso de Inteligencia Computacional en la Universidad PedagÃ³gica y TecnolÃ³gica de Colombia (UPTC).

---